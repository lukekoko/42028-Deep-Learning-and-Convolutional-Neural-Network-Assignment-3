{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHjl0J0sw5Wx",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxrTvMjickuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import math, numpy as np\n",
        "import sklearn.datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import keras\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from pathlib import Path\n",
        "\n",
        "from keras.utils import plot_model\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import HTML, display, clear_output, SVG"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aArqyhbIb0zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Path('/content/weights').mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TghLdIPPw1_Y",
        "colab_type": "text"
      },
      "source": [
        "# Setting up dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_tJofeSm3_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download images from github\n",
        "!git clone https://github.com/lukekoko/42028-Deep-Learning-and-Convolutional-Neural-Network-Assignment-3.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJmaSaThnyq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get paths for directories\n",
        "base_dir = './42028-Deep-Learning-and-Convolutional-Neural-Network-Assignment-3/dataset/'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Directory with our training covid pictures\n",
        "train_covid_dir = os.path.join(train_dir, 'covid19')\n",
        "\n",
        "# Directory with our training normal pictures\n",
        "train_normal_dir = os.path.join(train_dir, 'normal')\n",
        "\n",
        "# Directory with our test covid pictures\n",
        "test_covid_dir = os.path.join(test_dir, 'covid19')\n",
        "\n",
        "# Directory with our test normal pictures\n",
        "test_normal_dir = os.path.join(test_dir, 'normal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE3zTM4TdXbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data generation\n",
        "train_datagen = ImageDataGenerator(rescale=1/255, \n",
        "                                   rotation_range=20, \n",
        "                                   width_shift_range=0.2, \n",
        "                                   height_shift_range=0.2, \n",
        "                                   horizontal_flip=True, \n",
        "                                   vertical_flip=True, \n",
        "                                   fill_mode='nearest', \n",
        "                                   zoom_range=0.2, \n",
        "                                   validation_split=0.2)\n",
        "# validation_datagen = ImageDataGenerator(rescale=1/255,validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "test_dataset = test_datagen.flow_from_directory(batch_size=32,\n",
        "                                                directory=test_dir,\n",
        "                                                shuffle=True,\n",
        "                                                target_size=(150,150),\n",
        "                                                class_mode='binary')\n",
        "\n",
        "training_dataset = train_datagen.flow_from_directory(batch_size=32,\n",
        "                                                directory=train_dir,\n",
        "                                                shuffle=True,\n",
        "                                                target_size=(150,150),\n",
        "                                                subset=\"training\",\n",
        "                                                class_mode='binary')\n",
        "\n",
        "validation_dataset = train_datagen.flow_from_directory(batch_size=32,\n",
        "                                                directory=train_dir,\n",
        "                                                shuffle=True,\n",
        "                                                target_size=(150,150),\n",
        "                                                subset=\"validation\",\n",
        "                                                class_mode='binary')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhepYobUwwkM",
        "colab_type": "text"
      },
      "source": [
        "# Inception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJkXio5zEwpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weightFilepath = '/content/weights'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDIRRWAkvG9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "conv_base = InceptionV3(weights='imagenet',include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "model_inception = models.Sequential()\n",
        "model_inception.add(conv_base)\n",
        "model_inception.add(layers.Flatten())\n",
        "model_inception.add(layers.Dense(256, activation='relu'))\n",
        "model_inception.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBSG2ASQvX_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in conv_base.layers[:-4]:\n",
        "    layer.trainable = True\n",
        " \n",
        "# Check the trainable status of the individual layers\n",
        "# for layer in conv_base.layers:\n",
        "#     print(layer, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsVM8HsSFmFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_inception.summary()\n",
        "\n",
        "plot_model(model_inception, to_file='Inectpion.png', show_layer_names=True, show_shapes=True, rankdir='TB')\n",
        "SVG(model_to_dot(model_inception, show_layer_names=True, show_shapes=True, rankdir='TB').create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVBgD0hcv7uP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_inception.compile(loss='binary_crossentropy',\n",
        "              # optimizer='adam',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k40a2muSbh2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# callback checkpoint\n",
        "\n",
        "filepath = weightFilepath + '/weights_{epoch:02d}-{val_acc:.2f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD5CtHhIv_Zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_inception = model_inception.fit(\n",
        "      training_dataset,\n",
        "      epochs=10,\n",
        "      validation_data=validation_dataset,\n",
        "      callbacks = [checkpoint],\n",
        "      verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpaUXNwqwI_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_inception.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-xuu0z6EZB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_inception.save(weightFilepath + '/model1save.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9AIJuJ0bXuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history_inception.history['acc']\n",
        "val_acc = history_inception.history['val_acc']\n",
        "loss = history_inception.history['loss']\n",
        "val_loss = history_inception.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDBZJaMOa4NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelArray = dict((v,k) for k,v in training_dataset.class_indices.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIpw1G6TvCzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelArray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-b89Rlra6x6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagesForPrediction = test_dataset\n",
        "x, y = imagesForPrediction.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-02K38mNbK2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predictions on images from test set using baseline pretrained\n",
        "for i in range(0,32):\n",
        "    image = x[i]\n",
        "    label = labelArray[y[i]]\n",
        "    prediction = model_inception.predict_classes(np.expand_dims(x[i], axis=0))\n",
        "    predLabel = labelArray[prediction[0][0]]\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Prediction: {}, Actual: {}\".format(predLabel, label))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBiUoIKkhwEV",
        "colab_type": "text"
      },
      "source": [
        "# Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I57uNwMHid4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnxJP1znhyKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet_conv_base = ResNet50(weights='imagenet',include_top=False, input_shape=(150,150, 3))\n",
        "\n",
        "for layer in resnet_conv_base.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "    \n",
        "model_resnet = models.Sequential()\n",
        "model_resnet.add(resnet_conv_base)\n",
        "model_resnet.add(layers.Flatten())\n",
        "model_resnet.add(layers.Dense(256, activation='relu'))\n",
        "model_resnet.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXI_ma-xiFEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_resnet.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG-_Wo3ViPE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_resnet = model_resnet.fit(\n",
        "      training_dataset,\n",
        "      # steps_per_epoch=2,  # 2000 images = batch_size * steps\n",
        "      epochs=10,\n",
        "      validation_data=validation_dataset,\n",
        "      # validation_steps=50,  # 1000 images = batch_size * steps\n",
        "      verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6k3lkHMlHrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_resnet.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T9d1XHdj5id",
        "colab_type": "text"
      },
      "source": [
        "# VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPntJ6SnkQSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import VGG16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcRkKHK1j8vZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_conv_base = VGG16(weights='imagenet',include_top=False, input_shape=(150,150, 3))\n",
        "\n",
        "for layer in vgg16_conv_base.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "    \n",
        "model_vgg16 = models.Sequential()\n",
        "model_vgg16.add(resnet_conv_base)\n",
        "model_vgg16.add(layers.Flatten())\n",
        "model_vgg16.add(layers.Dense(256, activation='relu'))\n",
        "model_vgg16.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwutN485kEZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_vgg16.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnhH3FfpkHXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_vgg16 = model_vgg16.fit(\n",
        "      training_dataset,\n",
        "      # steps_per_epoch=2,  # 2000 images = batch_size * steps\n",
        "      epochs=10,\n",
        "      validation_data=validation_dataset,\n",
        "      # validation_steps=50,  # 1000 images = batch_size * steps\n",
        "      verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu7ZOpOilDoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_vgg16.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erOJwz5uFw-o",
        "colab_type": "text"
      },
      "source": [
        "# AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2p14GvVKFFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data generation\n",
        "train_datagen = ImageDataGenerator(rescale=1/255, validation_split=0.2)\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255,validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "test_dataset_alexnet = test_datagen.flow_from_directory(batch_size=20,\n",
        "                                                directory=test_dir,\n",
        "                                                shuffle=True,\n",
        "                                                target_size=(224,224),\n",
        "                                                class_mode='binary')\n",
        "\n",
        "training_dataset_alexnet = train_datagen.flow_from_directory(batch_size=20,\n",
        "                                                directory=train_dir,\n",
        "                                                shuffle=True,\n",
        "                                                target_size=(224,224),\n",
        "                                                subset=\"training\",\n",
        "                                                class_mode='binary')\n",
        "\n",
        "validation_dataset_alexnet = train_datagen.flow_from_directory(batch_size=20,\n",
        "                                                directory=train_dir,\n",
        "                                                shuffle=True,\n",
        "                                                target_size=(224,224),\n",
        "                                                subset=\"validation\",\n",
        "                                                class_mode='binary')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prdFMDPqF0uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_alexnet = tf.keras.models.Sequential([\n",
        "    #Conv_1          #original model was built for input shape of 224X224\n",
        "    tf.keras.layers.Conv2D(96, (11,11),strides=4, padding='valid', activation='relu', input_shape=(224, 224, 3)),\n",
        "    # Pooling_1\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2),padding='valid'),\n",
        "    # Batch Normalisation_1\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Conv_2\n",
        "    tf.keras.layers.Conv2D(256, (5,5),strides=1, padding='valid', activation='relu'),\n",
        "    # Pooling_2\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2),padding='valid'),\n",
        "    #Batch Normalisation_2\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Conv_3\n",
        "    tf.keras.layers.Conv2D(384, (3,3),strides=1, padding='valid', activation='relu'),\n",
        "    # Batch Normalisation_3\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # Conv_4\n",
        "    tf.keras.layers.Conv2D(384, (3,3),strides=1, padding='valid', activation='relu'),\n",
        "    # Batch Normalisation_3\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    #conv_5\n",
        "    tf.keras.layers.Conv2D(256, (3,3),strides=1, padding='valid', activation='relu'),\n",
        "    #pooling_3\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2),padding='valid'),\n",
        "    #Batch Normalization_4\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    #Dense layer_1\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    #Dense layer_2\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    #Dense layer_3\n",
        "    tf.keras.layers.Dense(1000, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SS8JyiMF7eI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_alexnet.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOIg0nBuGEAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_alexnet = model_alexnet.fit(\n",
        "      training_dataset_alexnet,\n",
        "      #steps_per_epoch=1000,  # 2000 images = batch_size * steps\n",
        "      epochs=10,\n",
        "      validation_data=validation_dataset_alexnet,\n",
        "      # validation_steps=50,  # 1000 images = batch_size * steps\n",
        "      verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMbwVJ82GpQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history_alexnet.history['acc']\n",
        "val_acc = history_alexnet.history['val_acc']\n",
        "loss = history_alexnet.history['loss']\n",
        "val_loss = history_alexnet.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-A4BgTEgCOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_alexnet.evaluate(test_dataset_alexnet)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}